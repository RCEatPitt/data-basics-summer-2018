{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day Two - Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's agenda\n",
    "\n",
    "* Talk about üêº (not that kind of panda)\n",
    "* Pandas data structures\n",
    "* Reading and writing CSV files to disk\n",
    "* Exploring and summarizing data\n",
    "* Subsetting Data\n",
    "* Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, we need to load pandas into memory and give it the name \"pd\"\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving into Pandas\n",
    "\n",
    "* Pandas is a 3rd-party library for doing data analysis\n",
    "* It is a foundational component of Python data science\n",
    "* Developed by [Wes McKinney](http://wesmckinney.com/pages/about.html) while working in the finance industry, so it has some...warts\n",
    "* Vanilla Python (what we did yesterday) can do many of the same things, but Pandas does them *faster* and usually *easier*\n",
    "* To do this, pandas introduces a set of data structures and analysis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Pandas Data Structures\n",
    "\n",
    "* To understand Pandas, which is hard, it is helpful to start the data structures it adds to Python:\n",
    "    * Series - For one dimensional data (lists) \n",
    "    * Dataframe - For two dimensional data (spreadsheets)\n",
    "    * Index - For naming, selecting, and transforming data within a Pandas Series or Dataframe (column and row names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "\n",
    "* A one-dimensional array of indexed data\n",
    "* Kind of like a blend of a Python list and dictionary\n",
    "* You can create them from a Python list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regular Python list\n",
    "my_list = [0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "# Transform that list into a Series\n",
    "data = pd.Series(my_list)\n",
    "\n",
    "# Display the data in the series\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Series is a list-like structure, which means it is *ordered* \n",
    "* You can use indexing to grab items in a Series, just like a list\n",
    "* Those numbers next to the other numbers, that is the *index* to the series\n",
    "* It is best to use the `iloc` method to grab elements by their location in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the first element\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the first element using iloc\n",
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the 4th elemenet\n",
    "data.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Exercise\n",
    "* How might we grab the *last* element if we didn't know the length of the list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hint: think small\n",
    "# your code below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Exercise\n",
    "\n",
    "* Use index notation to grab the 2nd element of `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hint: the 2nd element is 0.50\n",
    "# your code below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Also, like lists, you can use *slicing* notation to grab sub-lists\n",
    "* Again, it is best to use the `.iloc` method\n",
    "\n",
    "#### Quick Exercise\n",
    "\n",
    "* Use slices to grab the 2nd and 3rd elements of this series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hint: the 2nd & 3rd elements are 0.50 and 0.75\n",
    "# your code below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index by name\n",
    "\n",
    "* Series also act like Python dictionaries, *ordered* python dictionaries\n",
    "* This means you can grab things by name in addition to location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regular Python Dictionary\n",
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "\n",
    "# Transform that dictionary into a Series \n",
    "population = pd.Series(population_dict)\n",
    "\n",
    "# Display the data\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can use indexing and slicing like above, but now with keys instead of numbers!\n",
    "* It is best to use the `.loc` method when looking up things by name instead of by number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the data value with the name \"California\"\n",
    "population.loc['California']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if you try an use a name when it wants\n",
    "population.iloc['California']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Like a Python dictionary, a Series is a list of key/value pairs\n",
    "* But these are *ordered*, which means you can do slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Exercise\n",
    "\n",
    "* Try slicing this series, but with keys instead of numbers!\n",
    "* Select a subset of the data using the Python slicing notation\n",
    "* Don't forget, use `loc`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hint: Use the same : notation, but use the state names listed above\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "* `DataFrames` are the real workhorse of Pandas and Python Data Science\n",
    "* We will be spending a lot of time with data inside of Dataframes, so buckle up!\n",
    "* `DataFrames` contain two-dimensional data, just like an Excel spreadsheet\n",
    "* In practice, a `DataFrame` is a bunch of `Series` lined up next to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with our population Series\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then create another Series for the area\n",
    "area_dict = {'Illinois': 149995, 'California': 423967, \n",
    "             'Texas': 695662, 'Florida': 170312, \n",
    "             'New York': 141297}\n",
    "area = pd.Series(area_dict)\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with a key:value for each column\n",
    "state_info_dictionary = {'population': population,\n",
    "                       'area': area}\n",
    "\n",
    "# Now mash them together into a DataFrame\n",
    "states = pd.DataFrame(state_info_dictionary)\n",
    "# Display the data\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pandas automatically lines everything up because they have shared index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of dictionaries that contain our data.\n",
    "# one dictionary per observation/row\n",
    "dead_people = [\n",
    "    {\"ssn\":1, \"first_name\": \"Bob\", \"last_name\": \"Jones\", \"age\": 200},\n",
    "    {\"ssn\":2, \"first_name\": \"Jane\", \"last_name\": \"Jones\", \"age\": 199},\n",
    "    {\"ssn\":3, \"first_name\": \"Ethel\", \"last_name\": \"Jones\", \"age\": 180},\n",
    "    {\"ssn\":4, \"first_name\": \"Hortense\", \"last_name\": \"Jones\", \"age\": 178},\n",
    "    {\"ssn\":5, \"first_name\": \"Vern\", \"last_name\": \"Jones\", \"age\": 178}\n",
    "]\n",
    "\n",
    "# create a Dataframe from a list of dictionaries\n",
    "pd.DataFrame(dead_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of lists, each sub-list is an observation/row\n",
    "dead_people = [\n",
    "    [1,\"Bob\",\"Jones\",200],\n",
    "    [2,\"Jane\",\"Jones\",199],\n",
    "    [3,\"Ethel\",\"Jones\",180],\n",
    "    [4,\"Hortense\",\"Jones\",178],\n",
    "    [5,\"Vern\",\"Jones\",178]\n",
    "]\n",
    "\n",
    "# specify the column names seperately\n",
    "column_names = [\"ssn\",\"first_name\", \"last_name\", \"age\"]\n",
    "\n",
    "# make a Dataframe with column names specified separately\n",
    "pd.DataFrame(dead_people, columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "* Pandas `Series` and `DataFrames` are containers for data\n",
    "* The Index (and Indexing) is the mechanism to make that data retrievable\n",
    "* In a `Series` the index is the key to each value in the list\n",
    "* In a `DataFrame` the index is the column names, but there is also an index for each row\n",
    "* Indexing allows you to merge or join disparate datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `loc` method I talked about above allows us to select specific rows and columns *by name*.\n",
    "* Use the syntax `[<row>,<column>]` with index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value of the population column from Illinois\n",
    "states.loc[\"Illinois\", \"population\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also be tricky and use more advanced syntax to do more advanced queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the area for states from Florida to Texas\n",
    "# this is two dimensional slicing\n",
    "states.loc[\"Florida\":\"Texas\", \"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the area for Florida and Texas\n",
    "# Use a list to select multiple specific values\n",
    "states.loc[[\"Florida\", \"Texas\"], \"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get area and population for Florida and Texas\n",
    "# use a \":\" to specify \"all columns\"\n",
    "states.loc[[\"Florida\", \"Texas\"], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is happening here is we are passing a list of names for the rows, and using the colon \":\" to say \"all columns\n",
    "* OK, this is neat, but let's move on to some *real* examples\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Files into a Dataframe\n",
    "\n",
    "* Once your data is in a Pandas `DataFrame` you can easily use a ton of analytical tools\n",
    "* You just have to get your data to fit into a dataframe\n",
    "* Getting data to fit is a big part of the \"data janitor\" work...it is the craft of data carpentry\n",
    "* However, as we will see, there is still a lot of carpentry work to do once your data fits into a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the file and load it into memory\n",
    "\n",
    "* Pandas provides some very handy functions for reading in CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a CSV files using the unix command head\n",
    "!head community-center-attendance.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is how we open a CSV file with pure Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the CSV module\n",
    "import csv\n",
    "\n",
    "#\n",
    "file_handler = open('community-center-attendance.csv')\n",
    "# Load the file into the CSV module\n",
    "reader = csv.reader(file_handler)\n",
    "\n",
    "# Read all the data into a variable as a list. look ma! one line!\n",
    "center_attendance_python = [row for row in reader]\n",
    "\n",
    "# close the file handler for good hygiene \n",
    "file_handler.close()\n",
    "\n",
    "\n",
    "# Print out the first five rows \n",
    "center_attendance_python[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pandas can do this much easier using the `read_csv()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open up the csv file the Pandas way\n",
    "center_attendance_pandas = pd.read_csv(\"community-center-attendance.csv\", \n",
    "                                       index_col=\"_id\") # use the column named _id as the row index\n",
    "# Display the first five rows\n",
    "center_attendance_pandas.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice that Pandas figured out there is a header row and it create a row index from one of the columns\n",
    "* Pandas also has a special function, `head(n)` for looking at the first *n* rows in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the head function to look at the \"head\" \n",
    "# of the dataframe. Default is 5 rows.\n",
    "center_attendance_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice the index starts at 1 instead of zero, that is because we told Pandas to use the \"_id\" column as the row index.\n",
    "* This is when it is important to understand the difference between `loc` and `iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select row by index name\n",
    "center_attendance_pandas.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select row by index location\n",
    "center_attendance_pandas.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and Summarizing data\n",
    "\n",
    "* Once your data has been loaded as a Dataframe, you can start using Pandas various functions to quickly explore your data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful functions for exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looking at parts of the Dataframe\n",
    "* `<dataframe>.head(n)` - look at the first n rows of the dataframe\n",
    "* `<dataframe>.tail(n)` - look at the last n rows of the dataframe\n",
    "* `<dataframe>.sample(n)` - randomly select n rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first 10 rows\n",
    "center_attendance_pandas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the last 5 rows\n",
    "center_attendance_pandas.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab 5 random rows\n",
    "center_attendance_pandas.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many rows and columns?\n",
    "* `<dataframe>.shape` - return the rows and columns as a python data structure (not a function!)\n",
    "* `<dataframe>.info()` - Display the datatypes of the index and columns as well as memory usage\n",
    "* `<dataframe>.describe()` - Compute summary statistics for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows and columns\n",
    "center_attendance_pandas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the datatypes\n",
    "center_attendance_pandas.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The output above shows us a lot of implementation details about our dataframe\n",
    "* Data types, number of rows and columns, and the datatype of the column\n",
    "* Also shows us memory usage, which is useful because memory is a limited resource\n",
    "\n",
    "* We can also start doing some computations on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics on the numerical columns\n",
    "center_attendance_pandas.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `describe()` function will automatically compute summary statistics for numerical columns and ignore categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Numerical Data\n",
    "\n",
    "* We can use traditional Python functions to get information about our Dataframe.\n",
    "* The `len()` function tells us the length of the sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a standard python function to get the length of the sequence\n",
    "len(center_attendance_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So this tells us our dataset has 18,367 rows.\n",
    "* But this is just information about the dataset itself, it doesn't tell us how many people visited community centers\n",
    "* How many people visited all the community centers for all time (in the dataset)?\n",
    "* First let's answer this using pure python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first ten rows of the data loaded in python\n",
    "center_attendance_python[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable to hold the total attendance\n",
    "total_attendance = 0\n",
    "\n",
    "# loop over the data that was loaded using pure python\n",
    "for row in center_attendance_python[1:]: # skip the header row using a list slice\n",
    "    # add the row count to the total, convert string to int\n",
    "    row_attendance = int(row[3])\n",
    "    total_attendance = total_attendance + row_attendance\n",
    "\n",
    "print(total_attendance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now here is how we do the exact same thing with Pandas üòÑ\n",
    "* This code selects the `attendance_count` column and then computes the sum of all the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the total attendance with the pandas sum function\n",
    "center_attendance_pandas['attendance_count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also look at the summary statistics individually\n",
    "* `<dataframe>[<column name>].mean()` - calculate the mean value for the column values\n",
    "* `<dataframe>[<column name>].std()` - calculate the standard deviation for the column values\n",
    "* `<dataframe>[<column name>].var()` - calculate the variance value for the column values\n",
    "* `<dataframe>[<column name>].median()` - calculate the median value for the column values\n",
    "* `<dataframe>[<column name>].min()` - calculate the minimum value for the column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean attendance per day at all community centers\n",
    "center_attendance_pandas['attendance_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation\n",
    "center_attendance_pandas['attendance_count'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance\n",
    "center_attendance_pandas['attendance_count'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median attendance per day at all community centers\n",
    "center_attendance_pandas['attendance_count'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum attendance at community centers\n",
    "center_attendance_pandas['attendance_count'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pandas is not only a tool for working with numerical data\n",
    "* Lots of functionality for manipulating categorical data too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Categorical Data\n",
    "\n",
    "* Just like before we can start counting the distribution of values in the column. \n",
    "* how many entries per community center (this isn't counting attendance but counting the number of rows per center)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The \"Pythonic way\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the counts\n",
    "center_counter = dict()\n",
    "\n",
    "# loop over the data\n",
    "for row in center_attendance_python:\n",
    "    center = row[2]\n",
    "    \n",
    "    # check to see if the gender is already in the diction\n",
    "    if center not in center_counter:\n",
    "        # create a new entry\n",
    "        center_counter[center] = 1\n",
    "    else:\n",
    "        # increment a new entry\n",
    "        center_counter[center] += 1\n",
    "\n",
    "# Display the dictionary \n",
    "center_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Pandas way is a bit easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing with pandas\n",
    "center_attendance_pandas['center_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data with GroupBy\n",
    "\n",
    "\n",
    "* A common pattern in data analysis is splitting data by a key and then performing some math on all of the values with that key and finally combining it all back together\n",
    "* This is commonly known in data circles as *split, apply, combine*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dataframe to illustrate GroupBy\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data': range(6),\n",
    "                   'things':[45,234,6,2,1324,345]}, columns=['key', 'data', 'things'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframes have a method, groupby(), that takes a column name be be the grouping key\n",
    "df.groupby('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cool, but what is that? Well, we need to tell Pandas what to *do* with the groups\n",
    "* This is where we get to the *apply* step\n",
    "* We need to specify what kind of aggregation, transformation, or computation to perform on the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tell pandas to add up all of the values for each key\n",
    "df.groupby('key').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_dataframe = df.groupby('key')\n",
    "grouped_dataframe.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table summarizes some other built-in Pandas aggregations:\n",
    "\n",
    "| Aggregation              | Description                     |\n",
    "|--------------------------|---------------------------------|\n",
    "| ``count()``              | Total number of items           |\n",
    "| ``size()``               | Total number of items w/ NaNs   |\n",
    "| ``first()``, ``last()``  | First and last item             |\n",
    "| ``mean()``, ``median()`` | Mean and median                 |\n",
    "| ``min()``, ``max()``     | Minimum and maximum             |\n",
    "| ``std()``, ``var()``     | Standard deviation and variance |\n",
    "| ``mad()``                | Mean absolute deviation         |\n",
    "| ``prod()``               | Product of all items            |\n",
    "| ``sum()``                | Sum of all items                |\n",
    "\n",
    "These are all methods of ``DataFrame`` and ``Series`` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Exercise\n",
    "* Using the community center dataframe  try the aggregations above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try a aggregation function to see what it does by adding it after the period.\n",
    "\n",
    "center_attendance_pandas.groupby(\"key\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i0.kym-cdn.com/photos/images/newsfeed/001/296/855/bff.png)\n",
    "\n",
    "I am the Data and I speak for the [trees](https://data.wprdc.org/dataset/city-trees).\n",
    "\n",
    "Analyze PGH tree data with descriptive statistics. Answer the following questions using Pandas and the provided data about Pittsburgh's trees.\n",
    "\n",
    "* What is the average height and width of trees in Pittsburgh?\n",
    "* How tall is the tallest tree?\n",
    "* What is the tallest type of tree in pittsburgh on average?\n",
    "* Bonus: In what neighborhood is the widest tree? \n",
    "    * Hint: try the `idxmax()` to get the row id of the max value then select that row by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First step read csv into dataframe \n",
    "tree_data = pd.read_csv(\"Tree_data.csv\", low_memory=False)\n",
    "tree_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First things first, let's break it down!**\n",
    "\n",
    "![Break it down corgi](https://media0.giphy.com/media/TRff1szV5FYXu/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is the average height of Pittsburgh trees?\n",
    "# Your code below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How tall is the tallest tree?\n",
    "# Your code below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is the tallest type of tree in Pittsburgh on average?\n",
    "# Your code below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bonus: In what neighborhood is the widest tree?\n",
    "# Your code below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the average height of Pittsburgh trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step, select just the height values of the trees\n",
    "tree_heights = tree_data[\"height\"]\n",
    "\n",
    "# second step, compute the mean of those values using the max function\n",
    "tree_height_mean = tree_heights.mean()\n",
    "\n",
    "print(\"The average height of trees in Pittsburgh is\", tree_height_mean, \"feet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the average width of Pittsburgh trees?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step, select just the widths of the trees\n",
    "tree_widths = tree_data[\"width\"]\n",
    "\n",
    "# second step, compute the mean of those values using the mean fuctions\n",
    "tree_width_mean = tree_widths.mean()\n",
    "\n",
    "print(\"The average width of trees in Pittsburgh is\", tree_width_mean, \"feet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How tall is the tallest tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step, use idxmax to get the row index of the max value\n",
    "tallest_tree = tree_data[\"height\"]\n",
    "\n",
    "# second step, compute the max value of the heights \n",
    "tallest_tree_height = tree_heights.max()\n",
    "\n",
    "print(\"The tallest tree is\", tallest_tree_height, \"feet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On average, what is the tallest type of tree in Pittsburgh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step, group by the common name\n",
    "grouped_by_name = tree_data.groupby(\"common_name\")\n",
    "\n",
    "heights_by_name = grouped_by_name['height']\n",
    "\n",
    "average_heights_by_name = heights_by_name.mean()\n",
    "\n",
    "average_heights_by_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In what neighborhood is the widest tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first and second step, select the widths and use idxmax to get the row index of the max value\n",
    "widest_tree_id = tree_data[\"width\"].idxmax()\n",
    "\n",
    "# third step, select that row with by its index\n",
    "widest_tree = tree_data.loc[widest_tree_id]\n",
    "\n",
    "# forth step, select the neighborhood from that \n",
    "widest_tree_neighborhood = widest_tree['neighborhood']\n",
    "\n",
    "print(\"The widest tree is in\", widest_tree_neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data\n",
    "\n",
    "* It is sometimes helpful to think of a Pandas Dataframe as a little database. \n",
    "* There is data and information stored in the Pandas Dataframe (or Series) and you want to *retrieve* it.\n",
    "* Pandas has multiple mechanisms for getting specific bits of data and information from its data structures. \n",
    "\n",
    "### Masking: Filtering by Values\n",
    "\n",
    "* The most common is to use *masking* to select just the rows you want. \n",
    "* Masking is a two stage process, first you create a sequence of boolean values based upon a conditional expression--which you can think of as a \"query\"--and then you index your dataframe using that boolean sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the tree data again\n",
    "tree_data = pd.read_csv(\"Tree_data.csv\", low_memory=False)\n",
    "tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at all the columns\n",
    "tree_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How might we only look at trees in a particular neighborhood?\n",
    "* First step is to create a *query mask*, a list of `True/False` values for rows that satisfy a particular condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a query mask for trees in the Greenfield neighborhood\n",
    "neighborhood_query = tree_data['neighborhood'] == \"Greenfield\"\n",
    "neighborhood_query.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This tells us the row id and True or False if the neighborhood equals Greenfield\n",
    "* We can look up that row by index and see if it is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_data.loc[18872]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Yup! So now that we know the mask works, we can create a *subset* of our data containing Greenfield trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenfield_trees = tree_data[neighborhood_query]\n",
    "greenfield_trees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now you can do things like calculate the average height for just the Greenfield neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean height for greenfield trees\n",
    "greenfield_trees['height'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also combine query masks using boolean logic\n",
    "* Can we look at just the Norway Maples in Squirrel Hill South?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a query mask for squirrel hill south\n",
    "neighborhood_query = tree_data['neighborhood'] == \"Squirrel Hill South\"\n",
    "# create a query mask for norway maples\n",
    "tree_query = tree_data['common_name'] == \"Maple: Norway\"\n",
    "\n",
    "# apply both query masks using boolean AND\n",
    "norway_in_squirrel_hill = tree_data[neighborhood_query & tree_query]\n",
    "norway_in_squirrel_hill.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can also use computations to subset the data\n",
    "* For example, lets just select the tall trees over 100 feet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a query mask that selects trees with a height greater than 100 feet\n",
    "tall_trees_query = tree_data['height'] > 100\n",
    "\n",
    "# create a subset of just tall trees and display them\n",
    "tall_trees = tree_data[tall_trees_query]\n",
    "tall_trees.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It would appear there are five trees taller than 100 feet in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "![Tree pandas](http://i.imgur.com/wvfuagf.gif)\n",
    " Now that we know how to query Pandas Dataframes, let's try and get some answers!\n",
    "\n",
    "* Create a subset of the data that represents the most valuable trees in your favorite neighborhood.\n",
    "    * Hint: Use `tree_data.info()` to look for columns related to value.\n",
    "    * Hint: You will need to define a threshold for \"valuable\"\n",
    "* How many trees are in that subset?\n",
    "    * Hint: Use a standard Python function\n",
    "* How many trees of different types are in that subset?\n",
    "    * Hint: Look back to the Counting Categorical Data section "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First things first, let's break it down!**\n",
    "\n",
    "![Break it down corgi](https://media0.giphy.com/media/TRff1szV5FYXu/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write some pseudo code before you write some real code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the distribution of dollar value to get a sense of tree values\n",
    "tree_data['overall_benefits_dollar_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of data that represents the most valuable trees in your favorite neightborhood\n",
    "favorite_neighborhood_query = tree_data['neighborhood'] == \"Greenfield\"\n",
    "value_threshold = tree_data['overall_benefits_dollar_value'] > 100\n",
    "greenfield_money_trees = tree_data[favorite_neighborhood_query & value_threshold]\n",
    "\n",
    "# Look at the range of values for Greenfield trees\n",
    "greenfield_money_trees.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many trees in that subset?\n",
    "greenfield_money_trees['overall_benefits_dollar_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many trees of different types are in that subset?\n",
    "greenfield_money_trees['common_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data\n",
    "\n",
    "* Most of the previous stuff has focused on exploring the data through summary statistics and subsetting\n",
    "* However, another powerful element of Pandas is the ability to \n",
    "* Pandas provides a bunch of mechanisms for manipulating your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized Math Operations\n",
    "\n",
    "* When you perform a mathematical operation on a column, it will automatically apply that operation to every record/observation in the column.\n",
    "* This is called a *vectorized* operations\n",
    "* It is like a Python `for` loop, but much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the height/width ratio in a python loop\n",
    "# We use the iterrows() function to make the dataframe behave like a list\n",
    "for index, tree in tree_data.iterrows():\n",
    "    print(tree['height'] / tree['width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gah! Divide by zero, thats annoying. If we wanted to do this in pure python we'd have to add a bunch of error handling.\n",
    "* Or we could use PANDAS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_data['height'] / tree_data['width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pandas didn't even break a sweat AND it handled the divide by zero case!\n",
    "* Thanks Pandas! But how can we save that data?\n",
    "* You can easy just create a new column with a Python assignment operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column from the \n",
    "tree_data['height_width_ratio'] = tree_data['height'] / tree_data['width']\n",
    "\n",
    "tree_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can also use vector operations with scalar values\n",
    "* Pandas will automatically perform the operation on every value in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert feet to meters \n",
    "tree_data['metric_height'] = tree_data['height'] * 0.3048\n",
    "tree_data[['height', 'metric_height']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized String Operations\n",
    "\n",
    "* Sometimes you need to clean string or categorical data\n",
    "* Pandas has a set of String operations that do this work for you\n",
    "* Especially useful for handling bad data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ['peter', 'Paul', 'MARY', 'gUIDO']\n",
    "\n",
    "for s in data:\n",
    "    print(s.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But like above, this breaks very easily with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ['peter', 'Paul', None, 'MARY', 'gUIDO']\n",
    "\n",
    "for s in data:\n",
    "    print(s.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Pandas library has *vectorized string operations* that handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = pd.Series(data)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names.str.capitalize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Look ma! No errors!\n",
    "* Pandas includes a a bunch of methods for doing things to strings.\n",
    "\n",
    "|             |                  |                  |                  |\n",
    "|-------------|------------------|------------------|------------------|\n",
    "|``len()``    | ``lower()``      | ``translate()``  | ``islower()``    | \n",
    "|``ljust()``  | ``upper()``      | ``startswith()`` | ``isupper()``    | \n",
    "|``rjust()``  | ``find()``       | ``endswith()``   | ``isnumeric()``  | \n",
    "|``center()`` | ``rfind()``      | ``isalnum()``    | ``isdecimal()``  | \n",
    "|``zfill()``  | ``index()``      | ``isalpha()``    | ``split()``      | \n",
    "|``strip()``  | ``rindex()``     | ``isdigit()``    | ``rsplit()``     | \n",
    "|``rstrip()`` | ``capitalize()`` | ``isspace()``    | ``partition()``  | \n",
    "|``lstrip()`` |  ``swapcase()``  |  ``istitle()``   | ``rpartition()`` |\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "* In the cells below, try three of the string operations listed above on the Pandas Series `monte`\n",
    "* Remember, you can hit tab to autocomplete and shift-tab to see documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terry Gilliam',\n",
    "                   'Eric Idle', 'Terry Jones', 'Michael Palin'])\n",
    "monte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real *Messy* Data Example: Recipe Database\n",
    "\n",
    "* Let's walk through the recipe database example from the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/03.10-working-with-strings.html)\n",
    "* There are a few concepts and commands I haven't yet covered, but I'll explain them as I go along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes = pd.read_json(\"https://s3.amazonaws.com/openrecipes/20170107-061401-recipeitems.json.gz\", \n",
    "                       compression='gzip',\n",
    "                       lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have downloaded the data and loaded it into a dataframe directly from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are nearly 200,000 recipes, and 17 columns.\n",
    "Let's take a look at one row to see what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display the first item in the DataFrame\n",
    "recipes.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the first five items in the DataFrame\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information there, but much of it is in a very messy form, as is typical of data scraped from the Web.\n",
    "In particular, the ingredient list is in string format; we're going to have to carefully extract the information we're interested in.\n",
    "Let's start by taking a closer look at the ingredients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summarize the length of the ingredients string\n",
    "recipes['ingredients'].str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This shows us a statistical summary of the number of characters in the ingredients descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which row has the longest ingredients string\n",
    "recipes['ingredients'].str.len().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use iloc to fetch that specific row from the dataframe\n",
    "recipes.iloc[135598]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at the ingredients string\n",
    "recipes.iloc[135598]['ingredients']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* WOW! That is a lot of ingredients! That might need to be cleaned by hand instead of a machine\n",
    "* What other questions can we ask of the recipe data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many breakfasts?\n",
    "recipes.description.str.contains('[Bb]reakfast').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many have cinnamon as an ingredient?\n",
    "recipes.ingredients.str.contains('[Cc]innamon').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many misspell cinnamon as cinamon?\n",
    "recipes.ingredients.str.contains('[Cc]inamon').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "![Trash pandas](https://media0.giphy.com/media/Yck5MptncAGfS/giphy.gif)\n",
    "\n",
    "Trash pandas love food!\n",
    "\n",
    "* Let's see if we can draw out some additional information about the ingredients\n",
    "* Like how many for each recipe?\n",
    "\n",
    "* Use vectorized string operations to do the following:\n",
    "    * Split the ingredients string into a list of items\n",
    "    * Count the number of items in that list\n",
    "        * Hint: Try chaining multiple string operations\n",
    "        * Another hint: Don't forget `str` in your chain\n",
    "    * Compute summary statistics on that list\n",
    "    * Bonus: Create a new column \"number_of_ingredients\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is it. This is the answer.\n",
    "recipes['ingredients'].str.split(\"\\n\").str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pandas will F you up!](https://media1.giphy.com/media/EPcvhM28ER9XW/giphy.gif)\n",
    "\n",
    "* Pandas fucks up dirty data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['number_of_ingredients'] = recipes['ingredients'].str.split(\"\\n\").str.len()\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OK, thats it.\n",
    "* WE DID IT!\n",
    "\n",
    "![Celebration](https://media2.giphy.com/media/1ofR3QioNy264/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Readings and Resources\n",
    "\n",
    "* Python for Everybody - https://www.py4e.com/\n",
    "* Python Data Science Handbook - https://jakevdp.github.io/PythonDataScienceHandbook/index.html\n",
    "* Dataquest Online tutorials - https://Dataquest.io\n",
    "* Python Documentation - https://docs.python.org\n",
    "* Pandas Documentation - https://pandas.pydata.org/pandas-docs/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
